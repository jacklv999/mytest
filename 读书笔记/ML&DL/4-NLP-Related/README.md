## NLP相关

- #### [Seq2Seq解析](https://jacklv999.github.io/mytest/读书笔记/ML&DL/NLP/seq2seq解析.html) 

- #### Transformer

    - [Transformer笔记](https://jacklv999.github.io/mytest/读书笔记/ML&DL/NLP/Transformer笔记.html) 
    
- #### Attention机制
    - [Attention模型方法综述](https://mp.weixin.qq.com/s/sAYOXEjAdA91x3nliHNX8w) 
    - [一文读懂\<Attention is All You Need\> 附代码实现](https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247486960&idx=1&sn=1b4b9d7ec7a9f40fa8a9df6b6f53bbfb&chksm=96e9d270a19e5b668875392da1d1aaa28ffd0af17d44f7ee81c2754c78cc35edf2e35be2c6a1&scene=21#wechat_redirect) 
    - [为节约而生：从标准Attention到稀疏Attention](https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247498604&idx=1&sn=178bcb8827162a58a04d4ac131d03408&scene=0&ascene=37&devicetype=android-28&version=27000735&nettype=3gnet&abtest_cookie=BAABAAoACwASABMABAAjlx4AVpkeAM6ZHgD4mR4AAAA%3D&lang=zh_CN&pass_ticket=%2B33ttL5hp59cfjtaAq5o6kaSKL0Ty58q7M7hO1m7xKP6wvkQulpxPc0ZKIzza%2B6e&wx_header=1) 
    
- #### Word Embedding

    - [Word Embeding Review](./Word Embeding Review.html) 
    - [Note on BERT Embedding](./Note on BERT Embedding.html) 
    
- [Adapter架构](./Adapter架构.html) 

- [Prompt learning](./Prompt learning.html) 

- [实体关系抽取的现状和未来](./实体关系抽取的现状和未来.html) 

