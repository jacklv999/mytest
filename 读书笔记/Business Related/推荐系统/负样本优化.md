## 负样本优化

#### 1. 召回中的负样本优化

1. 展示未点击数据。常用的方式，但是会导致Sample Selection Bias，可以通过和其他负样本选择方法来缓解

2. 全局随机选择负例。从全局候选物料里面随机抽取item做为召回或者粗排的负例。例如 Youtube DNN双塔模型。虽然保证了输入数据的分布一致性，但这么选择的[负例](https://www.zhihu.com/search?q=负例&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2299284434})和正例差异太大，导致模型太好区分，可能学到的知识不够充分。

3. batch 内随机负例。输入数据只有正例，在训练的时候，在batch内随机采样一定比例的负样本，一定程度上可以解决Sample Selection Bias问题。

4. 展示数据内随机负例。在所有的展示物品中，随机选择负例。

5. 随机负例+热门打压。随机选择，但是越是流行的Item，越大概率会被选择作为负例。

6. hard负例。hard negative能够增加模型在训练时的难度，让模型关注细节。

    Airbnb根据业务逻辑来选取hard negative：

    - 增加与正样本同城的房间作为负样本，增强了正负样本在地域上的相似性，加大了模型的学习难度
    - 增加“被房主拒绝”作为负样本，增强了正负样本在“匹配用户兴趣爱好”上的相似性，加大了模型的学习难度。
    - 也可以将排序模型打分靠后的作为hard negtive

#### 2. 排序中的负样本优化

电商场景下，排序中中所周知的正例延迟上报问题，导致部分晚上报的正例在前面训练过程中作为了负例。

当天未购买可能并不一定是真正意义上的未购买,而可能是加购物车了但是没有当天下单, 而是过了一天下单, 而这样的标签如果我们直接默认其为负样本就会有正样本被当成负样本训练的问题，只是反馈延迟了。

1. 设置一个时间窗口，如果没有出现正例，就直接当作负例训练。
2. 如果正样本被当成了负样本训练，后续在训练的时候用两个正样本，一个抵消一个训练。
3. 将cvr预估拆分为两个模型，转化模型（conversion model，CVR）和 延迟模型（Delayed Feedback Model，DFM）。CVR模型用户预估用户最终是否发生转化，DFM则预估点击后第几天发生转化。
4. Faked nagative weighted。其实就是importance sampling，观察到的样本的分布是 biased distribution b,但是需要求解真实的样本的分布 p的期望。
5. Positive-Unlabeled Learning。通过修改损失函数进行优化。