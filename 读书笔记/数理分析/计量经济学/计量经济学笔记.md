# 计量经济学笔记

## 1.计量经济学的性质

1.横截面数据: 在给定时间点对一系列单位采集样本构成的数据集, 如: 某天全国省会城市的平均气温
2.时间序列数据：对某个体的多个变量不同时间的观测值所构成的数据集, 如: 去年北京的每天平均气温
3.混合横截面数据：混合不同时间点的横截面数据
4.面板数据：对多个个体的多个变量的跨时期跟踪数据集（数据单位通常被跟踪了一段时间）,如: 全国省会城市去年每天的平均气温

# 横截面数据分析

## 2.简单回归模型

#### 1.定义

又称双变量线性回归模型，表达式为 $$ Y = β_0 + β_1X_i + u_i$$ 

#### 2.普通最小二乘法的推导

普通最小二乘法的表达式为: 表达式为 $$ Y = β_0 + β_1X_i + u_i$$,其中各个参数的解释如下:

- 对于β<sub>0</sub>而言:  β<sub>0</sub> =  <SPAN style="TEXT-DECORATION: overline">y</SPAN> - β<sub>1</sub><SPAN style="TEXT-DECORATION: overline">x</SPAN>

- 对于β<sub>1</sub>而言:   $ β_1 = \frac{\sum_{i=1}^n(x_i-\overline{x})(y-\overline{y})}{\sum_{i=1}^n  (x_i-\overline{x})^2}=\rho_{xy}.\left(   \frac {\sigma_x}{\sigma_y}\right)$

- 对残差 **u<sub>i</sub>** 而言:  $$  \hat{y_i}  = y_i - \hat{y_i} = y_i - \hat{\beta_0}-  \hat{\beta_1}x_i $$

#### 3.OLS统计量的代数性质

- SST,即总平方和,度量了 y<sub>i</sub>中的总样本波动, 数学表达式为: $$SSR = \sum_{i=1}^n(y_i-\hat{y_i})^2$$
- SSE,即解释平方和,度量了 $$ \hat{y}$$ 的样本波荡, 数学表达式为: $$ SSE = \sum_{i=1}^n   (\hat{y_i} -  \overline{y_i} )^2    $$
- SSR,即残差平方和,度量 $$ \hat{u_i}$$ 的样本波动, 数学表达式为: $$ SSR = \sum_{i=1}^n \hat{u_i}^2= \sum_{i=1}^n(y_i - \hat{\beta_0}-\hat{\beta_1}x_i)^2$$

#### 4.拟合优度

拟合优度,有时又称判定系数,一般用 $$ R^2$$ 表示, 用数学表达式定义为: $$ R^2 = \frac{SSE}{SST}  = 1- \frac{SSR}{SST}  $$

#### 5.度量单位和函数形式

- 1.一般地, 当因变量的度量单位改变时(乘以常数C),则OLS的截距和斜率都扩大为原来的C倍
- 2.模型的拟合优度 $$ R^2$$ 不依赖于变量的度量单位

#### 6.含非线性因素的线性回归模型

| 模型          | 因变量 | 自变量 | 对$$β_1$$的解释                                  |
| ------------- | -----: | -----: | ------------------------------------------------ |
| 水平值-水平值 |      y |      x | $$\Delta y = \beta_1\Delta x  $$                 |
| 水平值-对数   |      y | log(x) | $$ \Delta y = (\frac{\beta_1}{100})\% \Delta x$$ |
| 对数值-水平值 | log(y) |      x | $$ \% \Delta y = (100 \beta_1)\Delta x   $$      |
| 对数-对数     | log(y) | log(x) | $$ \% \Delta y = \beta_1 \% \Delta x      $$     |

#### 7.OLS估计量的期望和方差

1.OLS的无偏性

- SLR1.线性于参数: 模型中因变量、自变量和误差的关系为 $$ y = \beta_0 + \beta_1 x + u $$
- SLR2.随机抽样
- SLR3.解释变量的样本有波动: x的样本结果不是完全相同的数值
- SLR4.零条件均值: 给定解释变量的任何值,误差的期望值都为零,即 $$E\left(\left.u \right|x \right)= 0  $$

利用假定SLR1-SLR4,对β~1~和β~0~的任何值,我们都有 $$ E(\hat{\beta_0}) = \beta_0 \quad  和 \quad E(\hat{\beta_1}) = \beta_1 $$

2.OLS估计量的方差

- SLR5.同方差性: 给定解释变量的任何值,误差都有相同的方差,即 $$ Var( \left. u \right| x) = \sigma^2 $$
- 同方差性对假定对于证明 $$\hat{\beta_0} 和 \hat{\beta_1} $$ 的无偏性毫无作用,但有助于简化计算

OLS估计量的抽样方差
$$
Var(\hat{\beta_1}) = \frac{\sigma_2}{\sum_{i=1}^n (x_i - \overline{x_i})^2} = \frac{\sigma_2}{SST_x}
$$
和
$$
Var  (\hat{\beta_0}) = \frac{\sigma^2\frac{\sum_{i=1}^nx_i^2} {n}} {\sum_{i = 1}^n  (x_i - \overline{x_i})^2}
$$
3.OLS的误差方差
对以上两式,我们可以很方便地把影响 $$ Var(\hat{\beta_1}) \quad 和 \quad Var(\hat{\beta_0})$$ 的因素分离出来,但是我们一般很难知道 $$ \sigma^2$$,所以需要使用观测数据估计 $$ \sigma^2$$
一般而言,我们可以得到以下表达式:
$$
\hat{\sigma}^2 = \frac   {\sum_{i = 1}^n  \hat{u}_i^2}  {n-2} = \frac {SSR}{n-2}
$$
和
$$
sd ( \hat{\beta_1}) = \frac {\sigma}{\sqrt{SST_x}}  \quad \\ 所以 \quad se( \hat{\beta_1}) = \frac {\hat{\sigma}}{\sqrt{SST_x }} = \frac {\hat{\sigma}}{\sqrt{\sum_{i=1}^n    ( x_i - \overline{x} )^2}}
$$

#### 8.过原点回归

在过原点回归的情形中,我们假定回归方程为 $$\tilde{y} = \tilde{\beta_1}x $$, 在这种情况下,我们可以得出 $$\tilde{ \beta_1}\quad 和 \quad R^2 $$ 如下示:
$$
\tilde{\beta_1} = \frac {\sum_{i = 1}^n x_i y_i}{\sum_{i = 1}^n x_i^2}  \quad 和\quad R^2 = 1- \frac {\sum_{i=1}^n  (y_i - \tilde{\beta_1}x_i)^2}{\sum_{i=1}^n  y_i^2}
$$



## 3.多元回归模型: 估计

#### 1.多元回归模型

多元回归可以表示就为 $$ y = \beta_0 + \beta_1x_1 + \beta_2 x_2 + \beta_3 x_3+ \cdots + \beta_k x_k + u$$, 其中条件期望表示为 $$ E( \left. u \right| x_1,x_2,\cdots,x_k) = 0  $$

#### 2.简单回归和多元回归估计值的比较

对于两者的估计值,存在如下关系: $$ \tilde{\beta_1} = \hat{\beta_1} + \hat{\beta_2}\tilde{\delta_1}    $$

- 在样本中,若X~2~对y的偏效应为零时, $$ \tilde{\beta_1} = \hat{\beta_1}$$, 即缺少变量不影响估计结果
- 样本中X~1~和X~2~不相关时,$$ \tilde{\beta_1} = \hat{\beta_1}$$ , 即缺少变量不影响估计结果

#### 3.拟合优度

在多元回归中,拟合优度为:
$$
R^2 = \frac{\sum_{i=1}^n  (y_i - \overline{y})(\hat{y_i}-\overline{\hat{y}})}    {(\sum_{i=1}^n(y_i-\overline{y})^2)(\sum_{i=1}^n(\hat{y_i}-\overline{\hat{y}})^2)}
$$

#### 5.模型误设

- 1.模型包含无关变量: 不影响模型的无偏性

- 2.模型遗漏变量: 遗漏变量偏误为 $$ Bais(\tilde{\beta_1}) = E(\tilde{\beta_1}) - \beta_1 = \beta_2 \tilde{\delta_1} $$

  - 1.若 β~2~ = 0 ,则有 $$\tilde{\beta_1}$$无偏

  - 2.若$$\; \tilde{\delta_1}  = 0$$, 即使 β~2~ 不为零,$$\; \tilde{\beta_1}$$也可能是无偏的

  - 3.存在遗漏变量的情况下,偏误方向的判定: 

  |        | Corr(x~1~,x~2~)>0 | Corr(x~1~,x~2~) < 0 |
  | ------ | ----------------- | ------------------- |
  | β~2~>0 | 偏误为正          | 偏误为负            |
  | β~2~<0 | 偏误为负          | 偏误为正            |

- 3.更一般的情况,若解释变量和误差存在相关,会导致所有OLS估计量产生偏差

- 4.误设模型中的方差: 大样本下对多重共线性的减弱和误差方差的原因使得前者的估计较后者更好

  - 1.$$\;\;Var(\hat{\beta_1}) = \frac{ \sigma^2}{SST_1(1-R_1^2)} $$

  - 2.$$\;\; Var(\tilde{\beta_1}) = \frac{\sigma^2}{SST_1 } $$

- 5.多元回归下的标准误:

  - 1.$$\;\; \hat{\sigma}^2 = \frac{\sum_{i = 1}^n}  {n-k-1 } = \frac{SSR}{n-k-1}    $$

  - 2.$$\;\; sd(\hat{\beta_j}) = \frac{\sigma}    {\sqrt{SST_j(1-R_j^2)} }  $$

  - 3.$$\;\; se(\hat{\beta_j}) = \frac{\hat{\sigma}}    {\sqrt{SST_j(1-R_j^2)} }  $$  或 $$ \; se(\hat{\beta_j}) = \frac{\hat{\sigma}}    {\sqrt{n} \; sd(x_j)\; \sqrt{(1-R_j^2)} }  $$



## 4.多元回归分析: 推断

#### 1.经典线性模型假定
- MLR.6 正态性假定: 总体误差独立于解释变量,且服从均值为零方差为 σ^2^的正态分布
MLR.1-MLR.6这六个假定被称为经典线性假定,在该假定下OLS估计量是最小方差无偏估计量, 可以表示为 
$$
\left. y \right| x ~ Normal(\beta_0 + \beta_1 x_1+ \beta_2 x_2+ \cdots +\beta_k x_k,\sigma^2)
$$

#### 2.对单个总体参数的检验: t检验
1.t统计量: $$ \quad t_\hat{\beta_j} == \frac{\hat{\beta_j}}{se(\hat{\beta_j})}$$
2.备择假设:  设定可行备择假设并设定t临界值

- 单侧备择假设: 假定 $$\quad H1: \beta_j > 0 \; $$, 拒绝法则为$$\quad t_{\hat{\beta_j}} > c $$,其中 C 为在给定显著性水平下的拒绝值,由t标准分布给出
- 参数小于零的单侧备择假设: 拒绝法则为 $$ t_{\hat{\beta_j}} < -c $$, C的值同样由标准分布给出
- 双侧备择假设: 假定 $$\quad \beta_j \neq 0 $$,拒绝法则为: $$ \quad \left| t_{\hat{\beta_j}} \right| > C $$
- 关于 β 的其他检验: 假定 $$ \quad H_0: \beta_j = a_j  \; $$, 则t统计量为 $$\; t = \frac{\hat{\beta_j} - a_j}{se(\hat{\beta_j})} \;$$

#### 3.置信区间
置信区间表达式为 $$ \; \hat{\beta_j} \pm c \cdot se(\hat{\beta_j}) $$

#### 4.参数线性组合的检验
1.方法一
 - 原假设: $$ \; \beta_1 = \beta_2 \;$$
 - 标准化t统计量: $$ t =  \frac {\hat{\beta_1} - \hat{\beta_2}}{se(\hat{\beta_1}-hat{\beta_2})} \; $$, 其中 $$\;se(\hat{\beta_1}-hat{\beta_2}) = \sqrt{[se(\hat{\beta_1})]^2 + [se(\hat{\beta_2})]- 2s_12 } \; $$

2.方法二
- 构建回归方程: $$ y = \beta_0 + \theta x_1 + \beta_2 (x_1 + x_2) + \cdots + \beta_k x_k + u$$
- 对该方程的 θ 参数做t检验

#### 5.对多个线性约束的检验: F检验
- 对多个参数做出假设: 原假设为 $$ \; H_0 : \beta_1 = 0 ,\beta_2 = 0,\beta_3 = 0 $$
- 构建不含以上参数的回归方程: $$ y = \beta_0 + \beta_4 x_4 + u $$
- 定义F统计量为: $$ F = \left. \frac{SSR_r - SSR_ur}{q} \right/ \frac{SSR_ur}{n-k-1} \quad $$(其中 r 指restrict)
- F 统计量的R^2^型: $$ F = \left. \frac{R_r^2 - R_{ur}^2}{q} \right/ \frac{1- R_{ur}^2}{n-k-1} \quad $$

#### 6.回归整体显著性的F检验
- 1.假设受约束模型: y = β~0~ + u
- 2.F统计量为 $$ F =  \left. \frac{R^2}{k}  \right/ \frac{1-R^2}{n-k-1} $$



## 5.多元回归分析: OLS的渐进性

#### 1.OLS的渐进偏误
- 样本量无限扩大时,存在: $$ plim\hat{\beta_1} - \beta_1 = \frac{Cov(x_1,u)}{Var(x_1)} $$
- 斜率回归表达式为: $$ plim\hat{\beta_1} = \beta_1 + \beta_2 \delta_1 $$
- OLS的渐进正态表明: t统计量检验和F统计量检验与经典线性检验一致

#### 2.拉格朗日乘数检验
- 1.对H~0~受限模型回归,并保存残差 $$ \tilde{u} $$
- 2.将  $$ \tilde{u} $$ 对所有自变量进行回归,并得到 R^2^, 记为 R~u~^2^
- 3.计算 LM = nR~u~^2^
- 4.将 LM 值与 $$ \chi_q^2 $$中适当的临界值c比较, 若 LM>C 则拒绝H~0~,否则不能拒绝



## 6.多元回归分析: 深入专题

#### 1.测度单位对OLS统计量的分析
- 1.改变测度单位不影响R^2^, 在对数和普通形式中均是如此
- 2.对于不同自变量单位的变化,可以使用正则化的方式处理,以方便对比不同变量

#### 2.对函数形式的进一步讨论
- 1.对数形式因变量: 有助于减少异方差性(自变量非全正),有助于减少极端值的影响
- 2.含二次项模型:  $$ \Delta \hat{y} \approx ( \hat{\beta_1} + 2\hat{\beta_2}x)\Delta x $$
- 3.含交互项模型: 交互效应
- 4.调整 R^2^ : 用于抵消过多变量导致的R^2^上升

  - 1.SST形式: $$ \; \; \overline{R^2} = 1 - \frac{\hat{\sigma^2}}{\left. SST \right/ (n-1)} $$

  - 2.R^2^形式: $$ \; \; \overline{R^2} = 1 - \frac{(1-R^2)(n- 1)}{n - k -1} $$
- 5.回归分析中控制因素过多

  - 1.使用调整R^2^控制

  - 2.引入与Y有关,但与我们关心的因素无关的自变量: 有助于提高R^2^,但不会导致多重共线性

#### 3.预测和残差分析
- 1.预测区间为: $$\quad  \hat{y}^0  \pm t_{0.025} \cdot se(\hat{e}^0) $$ , 其中$$ se(\hat{e}^0) = \sqrt{[se(\hat{y}^0 )]^2 + \hat{\sigma_2}}$$
- 2.残差分析: &emsp;对一系列预测的残差进行分析以确定低估和高估的情形
- 3.当因变量为 log(y)  对 y 的预测:  
  - 1.通过log y 对 x~1~, x~2~, .... , x~k~ 的回归得到拟合值 $$\widehat{logy_i }   \; \; 和   \; \;  残差 \hat{u_i} $$
  - 2.求出$$\hat{\alpha_0} $$:   其中 $$\; \hat{\alpha_0}  =  \frac{\sum_{i=1}^n exp(\hat{u_i)}}{n}$$
  - 3.计算$$\widehat{logy}$$: 其中 $$ \widehat{logy} = \hat{\beta_0}x_0 + \hat{\beta_1} x_1+ \cdots + \hat{\beta_k} x_k $$
  - 4.计算预测值  $$\hat{y}$$ :  其中 $$ \hat{y} = exp(\frac{\sigma^2}{2}) exp(\widehat{logy}) $$



## 7.含有定性信息的多元回归:  虚拟变量

#### 1.对虚拟变量

- 虚拟变量的数量为 n-1, 其中 n 为总二值变量数

- 对序数信息

  - 1.可以使用 虚拟变量 表示序数信息, 则每一虚拟变量的 β 值即代表该信息的偏效应

  - 2.多斜率方程:  使用 y = β~0~ + δ~0~ x~1~ + ( β~1~ + δ~1~ x~1~ ) x~2~ + u 表示多斜率方程

#### 2.检验不同组的回归函数的区别

- 1.令g = 1 和 g = 2 ,得到回归方程 :  $$ y = \beta_{g,0} + \beta_{g,1}x_1 + \beta_{g,3} x_3+ \cdots  +\beta_{g,k}x_k + u $$

- 2.对两方程回归得到 SSR~1~ 和 SSR~2~ , 同时合并两方程回归得到 SSR~p~ , 可以得到邹至庄统计量:

  $ F= \frac{SSR_p - SSR_1 - SSR_2}{SSR_1 + SSR_2} \;\cdot \; \frac{n - 2(k+1)}{k+1}  $



## 8.异方差性

#### 1.异方差性的影响

异方差不会导致OLS估计量产生偏误或不一致性,但是缺失相关解释变量会导致该情况

#### 2.OLS估计量的异方差稳健推断

- 1.对 $$Var(\hat{\beta_1}) $$ 的有效估计量:  $$ \frac{\sum_{i = 1}^n(x_i - \overline{x})^2\hat{u_i}^2}{SST_x^2} $$
- 2.异方差稳健的t统计量:  $$ t = \frac{估计值 - 假设值}{标准误} $$, 其中上式的平方根即为标准误
- 3.异方差稳健的F统计量:  F统计量在异方差下通常都不是有效的
- 4.异方差稳健 的LM统计量:  
  - 1.从假设 H~0~ 的约束模型中得到 $$ \tilde{u} $$
  - 2.将原假设中被排除的每个自变量分别对原假设包含的自变量进行回归, 得到其残差( r~1~, r~2~, ...r~q~)
  - 3.LM统计量为 :  n - SSR~1~ , 其中 SSR~1~为 $$ \tilde{u} $$ 对 r~j~ 与$$ \tilde{u} $$ 的乘积做回归

#### 3.对异方差的检验

- 1.布罗施-帕甘检验
  - 1.回归运算得 $$ \hat{u}^2$$
  - 2.使用  $$ \hat{u}^2$$ 对 所有自变量做回归得到 $$  R_{\hat{u}^2}^2  $$
  - 3.所以 F 统计量为 $$ F = \frac{  R_{\hat{u}^2 }^2 }{k} \; . \; \frac{1-  R_{\hat{u}^2}^2 }{n -k -1}$$ , LM统计量为: $$ n \cdot   R_{\hat{u}^2}^2 $$ , 其中 LM统计量即为布罗施-帕甘检验

- 2.怀特检验
  - 1.做OLS回归得到 $$ \hat{u}^2  \; \; 和 \; \; \hat{y}^2 $$ 
  - 2.做OLS回归 :  $$ \hat{u}^2 = \delta_0 + \delta_1 \hat{y} + \delta_2 \hat{y}^2 + 误差项 $$ , 并得出 $$  R_{\hat{u}^2}^2 $$ 
  - 3.构造F统计量或LM统计量(前者使用F~2,n-3~ , 后者使用 $$ \chi_{2}^2$$ 分布) 

- 3.加权最小二乘法估计
  - 1.将 y 对 x~1~,x~2~,...,x~k~做回归并得到残差 u 
  - 2.用 log(u^2^) 对 x~1~,x~2~,...,x~k~ 做回归, 并得到拟合值 g~i~  
  - 3.计算加权数为: h = exp(gi) , 得到加权数位 1/h~i~ 

#### 4.异方差函数误设
- h(x)函数误设不会使的WLS的估计量产生偏误和不一致
- h(x)函数误设会导致所有的WLS标准误和检验统计量不可靠,且其有效性不一定会比OLS更好

#### 5.存在异方差时的预测和预测区间
- 异方差下的预测区间为 $$ \; \hat{y^0} \pm t_0.025 \cdot se(\hat{e_0})$$,  其中$$ \quad se(\hat{e_0}) = \sqrt{se(\hat{y_0})^2 + \hat{\sigma}^2h(x)}$$ 
- 预测值为:  $$  \hat{y_i} = exp(\widehat{logy_i} + \hat{\sigma^2}\frac{\hat{h_i}}{2}) $$



## 9.模型设定和数据问题的深入讨论

#### 1.函数形式误设

- 1.一般检验: RESET检验

  - 构建方程: $$ \;\;   y = \beta_0 + \beta_1x_1 + \cdots+\beta_kx_k + \delta_1\hat{y}^2 + \delta_2\hat{y}^2 + u  $$
  - 检验  $$ \delta_1 = 0, \;\delta_2 = 0 $$ 的F统计量

- 2.对非嵌套模型的检验
  - 1.构建综合模型: 将所有情况都作为一个特殊情况包含在内并做检验
  - 2.戴维斯-麦金农检验: 
    - 构建两不同模型: $$ \quad  y = \beta_0 + \beta_1x_1+\cdots+ \beta_kx_k + u $$   和  $$ y = \beta_0 + \beta_1log(x_1)+\cdots+ \beta_klog(x_k) + u $$
    - 构建检验模型:  $$ y = \beta_0 + \beta_1x_1+\cdots+ \beta_kx_k + \theta_1\hat{y} + u   $$ , 对$ \theta_1$ 做显著性检验,  其中 $ \hat{y} $ 为另一模型的拟合值

#### 2.对无法观测的变量使用代理变量

- 1.使用代理变量
- 2.使用滞后因变量作为代理变量:  滞后因变量可以代表某些未被察觉的解释变量,  如: $y_{-1}$ 

#### 3.有测量误差时OLS的性质

- 1.因变量中存在测量误差:  若因变量测量误差与解释变量相关则导致OLS偏误, 否则无影响
- 2.解释变量中的测量误差
  - 1.测量误差与解释变量无关:  不影响OLS偏误
  - 2.测量误差与解释变量相关:  OLS统计量为有偏且不一致的估计量

#### 4.数据缺失,和非随机样本

- 1.随机数据缺失:  不影响OLS估计量, 引入"数据缺失指标(m~k~,当数据缺失时为1) " 

- 2.非随机样本:  若为内生样本, 除采用分层抽样等必产生偏误

#### 5.异常观测
- 1.对普通最小二乘估计
  - 1.分别报告包含异常观测和不包含异常观测的OLS结果
  - 2.学生化残差:  定义虚拟变量对异常观测取1(其他观测取0), 通过OLS得到其估计值
  - 3.对变量取对数:  对数可以显著减少数据的取值范围, 缩小异常观测的影响

- 2.使用最小绝对离差估计:  $min \sum_{i=1}^n \left| y_i -b_0 -b_1x_{i1} - \cdots -b_{k}x_{ik}   \; \right|$ 



## 10.时间序列数据的基本回归分析

#### 1.有限分布滞后模型

- 在普通回归中引入"滞后变量", 如: y = ay~-1~ + by~-2~  + ...
- 在线性模型中: 短期乘数: a; 长期乘数: a+b...; 在对数模型中, 我们视之为短期弹性和长期弹性

#### 2.事件与指数研究

- 事件研究: 研究某事件或时期的影响时, 可设定虚拟变量以区分该时期
- 指数研究: 指数能非常好地拟合时间序列数据

#### 3.趋势和季节性

- 1.趋势:
  - 1.引入趋势变量:  y = ax~1~ + bx~2~ + ... + ct + u
  - 2.确定无趋势影响系数
    - 1.用y, x~1~, x~2~ 等分别对时间t回归并得到残差 y~t1~, x~t1~, x~t2~ ,
    - 2.再使用y~t1~对 x~t1~, x~t2~ 回归得到无趋势影响系数
  - 3.有趋势影响时R^2^ 的计算: 
    - 1.用y对t回归得到残差 y~t~
    - 2.将 y~t~ 对x~1~, x~2~, t 回归,  可以得到:  R^2^ = $1 -  \frac{SSR}{\sum_{t = 1}^n y_t^2} $ 
- 2.季节性: 引入季节性虚拟变量



## 11.OLS用于时间序列数据的其他问题

#### 1.平稳和弱相关时间序列

- 1.平稳和非平稳时间序列
  - 1.平稳随机过程:  指概率分布跨时间段稳定的时间序列过程(序列前后移动时联合概率分布不变)
  - 2.协方差平稳过程:  该随机过程的均值和方差不随时间变化
- 2.弱相关序列:  可表达为 $  \lim_{h \to \infin} Corr (x_t,x_{t+h}) = 0  $ , ==**弱相关时间序列的OLS估计仍是一致的**==

#### 2.回归分析中使用高度持续性时间序列

- 1.单位根过程: 指可以表达为 $\; y_t = \rho_1 y_{t-1} + e_t \;$ 的过程, 其中 ρ~1~ 为常数
  - 1.随机游走过程:  指可表达为 $\; y_t = y_{t-1} + e_t \;$ 的过程,  e~t~ 是均值 0, 方差 σ^2^ 的独立同分布序列
  - 2.带截距的随机游走过程:  指可以表达为$ \;  y_t = \alpha_0+ y_{t-1} + e_t \;$ 的过程
- 2.高度持续性时间序列的变换
  - 1.相关概念: 弱相关即零阶单整, 即(0); 随机游走即一阶单整, 即I(1)
  - 2.一阶差分过程:  y~t~‘ = y~t~ - y~t-1~ , 高度持续性时间序列的水平值必须采用差分过程去掉线性趋势
- 3.判断时间序列是否为I(1):  通过对 y~t~ 和 y~t-1~ 的样本相关系数估计 ρ 值, 若 ρ>0.9 则认为是 I(1)

#### 3.动态完备模型和无序列相关

- 1.序列无关: 数学表达式为 $ E(u_t u_s|x_t, x_s) = 0 $ 
- 2.动态完备模型
  - 1.动态完备模型为: 满足 $ E( y_t|x_t, y_{t-1}, x_{t-1},... ) = E( y_t|x_t ) $ 
  - 2.一般认为动态完备模型不存在序列相关



## 12.时间序列中的序列相关和异方差性

#### 1.含序列相关误差时OLS的性质

- 1.无偏性和一致性
  - 1.若解释变量严格外生, 则无论误差中序列相关程度如何, β~j~ 都是无偏的
  - 2.放松严格外生条件, 若 E(u~t~|x~t~) = 0, 则数据弱相关时 β~j~ 是一致的(不一定无偏)
- 2.有效性和推断: 存在序列相关时, OLS的方差估计量都是有偏的
- 3.拟合优度:  只要数据是平稳和弱相关, R^2^ 和 调整R^2^ 则仍旧有效
- 4.出现滞后变量的序列相关
  - 1.表述: 若误差 u~t~ 服从AR(1)过程,则OLS估计量不一致
  - 2.原因: 若 e~t~ 与 y~t-1~ 不相关, Cov( y~t-1~, u~t~) = ρ Cov( y~t-1~, u~t-1~ ), 则除非 ρ = 0 , 否则OLS必不一致

#### 2.序列相关检验

- 1.回归元严格外生时
  - 1.做 y~t~ 对 x~t1~, x~t2~, ... , x~tk~ 的OLS回归得到残差 u~t~ .
  - 2.做 $ u_t = \rho u_{t-1} + e_t $ 的回归, 得到 ρ 值和 t 统计量 t~ρ~ .
  - 3.用 t 统计量检验原假设 ρ =! 0
- 2.经典假定条件下的德宾-沃森检验
  - 1.计算DW统计量: $ DW = \frac{\sum_{t = 2}^n (\hat{u}_t - \hat{u}_{t-1})}{\sum_{t = 1}^n \hat{u}_t^2} $ 
  - 2.ρ 与 DW 关系式为: $ DW  \approx 2(1 - \rho) $ 
  - 3.实际检验中一般给出 d~U~(上界) 和 d~L~(下界), DW < d~L~则拒绝H~0~, d~L~<DW<d~u~ 则无结论, d~u~<DW则不能拒绝
- 3.回归元不是严格外生时AR(1)序列相关的检验
  - 1.做 y~t~ 对 x~t1~, x~t2~, ... , x~tk~ 的OLS回归得到残差 u~t~ .
  - 2.做 $ u_t \;对\;  u_{t-1} ,\;x_{t1},\;x_{t2},\;...\;,x_{tk} $ 的回归, 得到 ρ 值和 t 统计量 t~ρ~
  - 3.用 t 统计量检验原假设 ρ =! 0
  - 附注: 必要时需使用 异方差-稳健的 t 统计量
- 4.更高阶序列相关的检验
  - 1.AR(q)序列相关检验
    - 1.做 y~t~ 对 x~t1~, x~t2~, ... , x~tk~ 的OLS回归得到残差 u~t~ .
    - 2.做 $ u_t \;对\;  u_{t-1} ,\;u_{t-2},\;...,u_{t-q},\;  x_{t1},\;x_{t2},\;...\;,x_{tk} $ 的回归
    - 3.计算上式中  $ \;u_{t-1} ,\;u_{t-2},\;...,u_{t-q}\;  $ 联合显著的 F 统计量
  - 2.LM检验量:  LM = (n-q) R~u~^2^ , 在原假设下 LM ~ $\chi_q^2$ 的分布做相应检验即可

#### 3.回归元严格外生时序列的修正

- 1.AR(1)模型中求最优线性无偏估计量
  - 1.用OLS估计量计算残差,并再次回归得到 $\hat{ρ}$ 
  - 2.对方程 $ \tilde{y}_t = (1-\hat{\rho})\beta_0 + \beta_1\tilde{x_t} + e_t $ 做回归, 其中 $ \; \tilde{y_t} = y_t -\hat{ \rho} y_{t-1} \;$, $ \; \tilde{x_t} = x_t - \hat{\rho} x_{x-1}\;$
  - 3.对 y~1~ 项, $ \;y_1 \sqrt{1-\hat{\rho}^2} \;  = \beta_0  \sqrt{1-\hat{\rho}^2} \;  + \beta_1x_1 \sqrt{1-\hat{\rho}^2} \;  + u_1 \sqrt{1-\hat{\rho}^2} \;    $ 
- 2.有AR(1)误差的可行GLS 估计
  - 1.用OLS估计量计算残差,并再次回归得到 $\hat{ρ}$
  - 2.对方程 $ \tilde{y}_t = (1-\hat{\rho})\beta_0 + \beta_1\tilde{x_{t1}} + \cdots + \beta_k \tilde{x_{tk}} + e_t $ 做回归, 得到标准误, t统计量等均有效
  - 3.上述方程直接回归为 科克伦-奥卡斯估计, 上述回归加上 y~1~ 项得到普莱斯-温斯顿估计
- 3.更高阶序列相关的修正
  - 1.在AR(2)过程中, 若 $ u_t = \rho_1 u_{t-1} + \rho_2 u_{t-2} + e_t $ 且 ρ~2~ > -1, ρ~2~ - ρ~1~ < 1, ρ~1~ + ρ~2~ < 1
  - 2.做OLS回归并对残差再次回归可得到 $ \hat{\rho}_1 \; 和 \; \hat{\rho_2} $ 
  - 3.做方程 $ \tilde{y}_t = \beta_0 (1 - \rho_1 - \rho_2) + \beta_1 \tilde{x} _t $ , 其中 $ \tilde{y}_ t = y_t - \rho_1 y_{t-1} - \rho_2\, y_{t-2} $ ,  $ \tilde{x}_ t = x_t - \rho_1 x_{t-1} - \rho_2\, x_{t-2} $ 

#### 4.OLS后的序列相关-稳健推断

- 1.用OLS估计得到 $se(\hat{β}_1),\;\hat{\sigma},\;\;和\; \; OLS残差$  
- 2.通过辅助回归:  x~t1~ 对 x~t2~, x~t3~, ... , x~tk~做回归得到残差 $ \hat{r}_t$, 然后构造 $\; \hat{\alpha}_t = \hat{r}_t\hat{u}_t  $
- 3.对g(多用$ 4\times\sqrt[2/9]{\frac{n}{100}} $ 整数部分), 并计算 $ \; \hat{v} = \sum_{t= 1}^n \hat{\alpha}_t^2 + 2\times\sum_{h = 1}^g [1-\frac{h}{g+1}] \times\sum_{t = h+1}^n\hat{\alpha}_t\hat{\alpha}_{t-h} $.
- 4.计算序列相关-稳健标准误 :  $ se_{稳健}(\hat{\beta}_1) = \sqrt{\hat{v}} \;\;\times\;\; (\frac{se(\hat{\beta_1})}{\hat{\sigma}})$ 

#### 5.时间序列回归中的异方差性

- 1.异方差检验
  - 1.首先检验误差的序列相关
  - 2.布罗施-帕甘异方差检验:  $ \; u_t^2 = \delta_0 + \delta_1 x_{t1} + \cdots + \delta_k x_{tk} + v_t $ ,以F统计量检验δ是否全零
- 2.自回归条件异方差: 自回归条件异方差不影响OLS的一致
- 3.具有异方差和AR(1)序列相关的可行GLS:
  - 1.用OLS估计并保留残差 $ \hat{u}_t$
  - 2.用$\;\log(\hat{u}_t)\;$对$ \; x_{t1}, x_{t2},\cdots,x_{tk} \;$回归得到拟合值, 记为 g~t~.
  - 3.求出 $\;\hat{h}_t\;$的估计值: $ \hat{h}_t = \exp(\hat{g}_t) $ .
  - 4.用标准科克伦-奥卡特或普莱斯-温斯顿方法估计:  $\; y_t  \sqrt[-\frac{1}{2}]{\hat{h}_t} = \beta_0 \sqrt[-\frac{1}{2}]{\hat{h}_t} + \beta_1 x_{t1} \sqrt[-\frac{1}{2}]{\hat{h}_t} + \cdots + \beta_k x_{tk} \sqrt[-\frac{1}{2}]{\hat{h}_t} + e_t$   






